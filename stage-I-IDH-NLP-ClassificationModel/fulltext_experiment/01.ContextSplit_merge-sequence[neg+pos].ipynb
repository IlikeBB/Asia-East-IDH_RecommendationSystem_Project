{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "568\n",
      "(2693, 3)\n"
     ]
    }
   ],
   "source": [
    "get_2693_sample_df = pd.read_csv('../dataset/PeriHD_InternalData_05-17.csv')\n",
    "get_2693_sample_df\n",
    "positive_context_split_csv = (get_2693_sample_df[get_2693_sample_df.label==1])['處置其他結束（描述）'].values.tolist()\n",
    "print(len(positive_context_split_csv))\n",
    "\n",
    "\n",
    "concat1 = pd.read_csv('/ssd8/chih/project/yadong/process_csv/PeriHD_not_markdata-sampe2000.csv')\n",
    "concat2 = pd.read_csv('/ssd8/chih/project/yadong/mark_csv/train_peri_mark_sample_693_JYY.csv')\n",
    "peri_filter_dataset = pd.concat([concat1, concat2])\n",
    "# peri_filter_dataset = peri_filter_dataset['處置其他結束（描述）']\n",
    "# peri_693_dataset = pd.read_csv('../mark_csv/train_peri_mark_sample_693_JYY.csv')[['truth', '處置其他結束（描述）']]\n",
    "# peri_filter_dataset = peri_693_dataset[peri_693_dataset['truth']=='Y']\n",
    "print(peri_filter_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先切割標記後的資料以確保訓練和驗證資料無重疊\n",
    "keyword_col = []\n",
    "for seq in peri_filter_dataset['處置其他結束（描述）'].values.tolist(): #逐筆搜尋pos\n",
    "    seq_sp = str(seq).replace(\"。\",\"，\").replace(\",\",\"，\").replace(\"\\n\",\"\").split('，')\n",
    "    temp_keyword = ''\n",
    "    for pos in positive_context_split_csv:\n",
    "        if str(pos) in seq_sp:\n",
    "            temp_keyword = temp_keyword + str(pos)+'，'\n",
    "    if len(temp_keyword)<1:\n",
    "        temp_keyword = 'Negative_Sequence'\n",
    "    keyword_col.append(temp_keyword)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "peri_filter_dataset['KeyWord_dict'] = keyword_col\n",
    "peri_filter_dataset = peri_filter_dataset[['處置其他結束（描述）', 'KeyWord_dict']]\n",
    "peri_filter_dataset['label'] = [0 if i =='Negative_Sequence' else 1 for i in peri_filter_dataset.KeyWord_dict.tolist()]\n",
    "data_train, data_test = train_test_split(peri_filter_dataset, test_size=0.1, random_state=42, stratify=peri_filter_dataset['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>處置其他結束（描述）</th>\n",
       "      <th>KeyWord_dict</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>透析後無不適，跌倒評估0項，紗布加壓止血，自行步行返家。</td>\n",
       "      <td>Negative_Sequence</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>AVF thrill(++)，離開HDR。</td>\n",
       "      <td>Negative_Sequence</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>HD畢無不適，右側perm cath Heparin lock存,紗布覆蓋,家人陪同離開。</td>\n",
       "      <td>Negative_Sequence</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>Fe-back 40mg iv at 20:20~21:20\\nHD畢，無不適情形，AVF ...</td>\n",
       "      <td>Negative_Sequence</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1927</th>\n",
       "      <td>HD畢，無不適情形，HF clear，AVF 已止血，thrill(++)，家屬陪同返家。</td>\n",
       "      <td>Negative_Sequence</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>透析後無不適，透析後評估項目0項，AVF已止血，perm-cath heparin lock...</td>\n",
       "      <td>Negative_Sequence</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>By order Feback40mg IV at15:34-16:34,現Perm cat...</td>\n",
       "      <td>Negative_Sequence</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>Fe back 40 nmng v at 15:15-16;15  HF clear AVF...</td>\n",
       "      <td>Negative_Sequence</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>Fe back 40 mg iv at 11:00-12:00\\n無不適情形，AVF已止血及...</td>\n",
       "      <td>Negative_Sequence</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>止血後AVF thrill++,go home</td>\n",
       "      <td>Negative_Sequence</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2423 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             處置其他結束（描述）       KeyWord_dict  \\\n",
       "1575                       透析後無不適，跌倒評估0項，紗布加壓止血，自行步行返家。  Negative_Sequence   \n",
       "409                               AVF thrill(++)，離開HDR。  Negative_Sequence   \n",
       "958       HD畢無不適，右側perm cath Heparin lock存,紗布覆蓋,家人陪同離開。  Negative_Sequence   \n",
       "279   Fe-back 40mg iv at 20:20~21:20\\nHD畢，無不適情形，AVF ...  Negative_Sequence   \n",
       "1927      HD畢，無不適情形，HF clear，AVF 已止血，thrill(++)，家屬陪同返家。  Negative_Sequence   \n",
       "...                                                 ...                ...   \n",
       "1075  透析後無不適，透析後評估項目0項，AVF已止血，perm-cath heparin lock...  Negative_Sequence   \n",
       "722   By order Feback40mg IV at15:34-16:34,現Perm cat...  Negative_Sequence   \n",
       "1001  Fe back 40 nmng v at 15:15-16;15  HF clear AVF...  Negative_Sequence   \n",
       "219   Fe back 40 mg iv at 11:00-12:00\\n無不適情形，AVF已止血及...  Negative_Sequence   \n",
       "1125                            止血後AVF thrill++,go home  Negative_Sequence   \n",
       "\n",
       "      label  \n",
       "1575      0  \n",
       "409       0  \n",
       "958       0  \n",
       "279       0  \n",
       "1927      0  \n",
       "...     ...  \n",
       "1075      0  \n",
       "722       0  \n",
       "1001      0  \n",
       "219       0  \n",
       "1125      0  \n",
       "\n",
       "[2423 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "COS_ = 1 # COS_=1: only sentence data, =2: do COS function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "merage_sentence = []\n",
    "for seq in range(len(data_test)):\n",
    "    if True:\n",
    "        rep_seq = data_test.iloc[seq]['處置其他結束（描述）']\n",
    "        rep_seq = str(rep_seq).replace(\"。\",\"，\").replace(\",\",\"，\").replace(\"\\n\",\"\").replace(\";\",\"，\").replace(\"；\",\"，\").split('，')\n",
    "        key_word = data_test.iloc[seq]['KeyWord_dict']\n",
    "        key_word = str(key_word).replace(\"。\",\"，\").replace(\",\",\"，\").replace(\"\\n\",\"\").replace(\";\",\"，\").replace(\"；\",\"，\").split('，')\n",
    "        key_word = [x for x in key_word if x != \"\"]\n",
    "    if COS_ ==1:\n",
    "        if len(rep_seq)!=1:\n",
    "            for i in range(len(rep_seq)):\n",
    "                new_sentence = rep_seq[i]\n",
    "                if (rep_seq[i] in key_word):\n",
    "                    merage_sentence.append(['Y',new_sentence])\n",
    "                elif len(rep_seq[i])>0:\n",
    "                    merage_sentence.append(['N',new_sentence])\n",
    "    elif COS_==2:\n",
    "        if len(rep_seq)!=1:\n",
    "            for i in range(len(rep_seq)-1):\n",
    "                new_sentence = rep_seq[i]+\"，\"+rep_seq[i+1]\n",
    "                if (rep_seq[i] in key_word) or (rep_seq[i+1] in key_word):\n",
    "                    merage_sentence.append(['Y',new_sentence])\n",
    "                elif len(rep_seq[i+1])>0:\n",
    "                    merage_sentence.append(['N',new_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.DataFrame(merage_sentence, columns=['Truth', '處置其他結束（描述）']).drop_duplicates(subset=['處置其他結束（描述）'])).to_csv(\"./dataset/pre-processing/PeriHD_Sentence-merge_internal-test[pos+neg-only-sentence].csv\", encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "merage_sentence = []\n",
    "for seq in range(len(data_train)):\n",
    "    rep_seq = data_train.iloc[seq]['處置其他結束（描述）']\n",
    "    rep_seq = str(rep_seq).replace(\"。\",\"，\").replace(\",\",\"，\").replace(\"\\n\",\"\").replace(\";\",\"，\").replace(\"；\",\"，\").split('，')\n",
    "    key_word = data_train.iloc[seq]['KeyWord_dict']\n",
    "    key_word = str(key_word).replace(\"。\",\"，\").replace(\",\",\"，\").replace(\"\\n\",\"\").replace(\";\",\"，\").replace(\"；\",\"，\").split('，')\n",
    "    key_word = [x for x in key_word if x != \"\"]\n",
    "    if COS_ ==1:\n",
    "        if len(rep_seq)!=1:\n",
    "            for i in range(len(rep_seq)):\n",
    "                new_sentence = rep_seq[i]\n",
    "                if (rep_seq[i] in key_word):\n",
    "                    merage_sentence.append(['Y',new_sentence])\n",
    "                elif len(rep_seq[i])>0:\n",
    "                    merage_sentence.append(['N',new_sentence])\n",
    "    elif COS_==2:\n",
    "        if len(rep_seq)!=1:\n",
    "            for i in range(len(rep_seq)-1):\n",
    "                new_sentence = rep_seq[i]+\"，\"+rep_seq[i+1]\n",
    "                if (rep_seq[i] in key_word) or (rep_seq[i+1] in key_word):\n",
    "                    merage_sentence.append(['Y',new_sentence])\n",
    "                elif len(rep_seq[i+1])>0:\n",
    "                    merage_sentence.append(['N',new_sentence])\n",
    "    # if seq==10:\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18975"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merage_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.DataFrame(merage_sentence, columns=['Truth', '處置其他結束（描述）']).drop_duplicates(subset=['處置其他結束（描述）'])).to_csv(\"./dataset/pre-processing/PeriHD_Sentence-merge_internal-train[pos+neg-only-sentence].csv\", encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1124, 2)\n",
      "(1011, 2) (113, 2)\n"
     ]
    }
   ],
   "source": [
    "get_1124_sample_df = pd.read_csv(\"../dataset/IntraHD_InternalData_05-17.csv\")\n",
    "# get_1124_sample_df = get_1124_sample_df.rename(columns={'truth':'label'})\n",
    "get_1124_sample_df = get_1124_sample_df.dropna()\n",
    "print(get_1124_sample_df.shape)\n",
    "data_train, data_test = train_test_split(get_1124_sample_df, test_size=0.1, random_state=42, stratify=get_1124_sample_df['label'])\n",
    "data_train.to_csv(\"./dataset/pre-processing/IntraHD_Sentence_internal-train.csv\", encoding='utf-8-sig', index=False)\n",
    "data_test.to_csv(\"./dataset/pre-processing/IntraHD_Sentence_internal-test.csv\", encoding='utf-8-sig', index=False)\n",
    "print(data_train.shape, data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', 1000)\n",
    "# pd.set_option('display.max_columns', 20)\n",
    "# data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yd_nlptf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "77a05f791b774c1311eb56e0a2c433b66341ac9a91a33433ad780b7802be94e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
