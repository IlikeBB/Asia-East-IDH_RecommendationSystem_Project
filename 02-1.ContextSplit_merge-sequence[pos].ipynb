{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5549, 3)\n",
      "666\n",
      "(2693, 3)\n"
     ]
    }
   ],
   "source": [
    "get_2693_sample_df = pd.read_excel('../mark_csv/revise5550_JYY0315_importantdata.xlsx')[['new_label', 'revised_Truth', '處置其他結束（描述）']]\n",
    "context_split_csv = get_2693_sample_df.rename(columns={'new_label':'label'})\n",
    "print(context_split_csv.shape)\n",
    "positive_context_split_csv = (context_split_csv[context_split_csv.revised_Truth=='Y'])['處置其他結束（描述）'].values.tolist()\n",
    "print(len(positive_context_split_csv))\n",
    "\n",
    "\n",
    "concat1 = pd.read_csv('/ssd8/chih/project/yadong/process_csv/PeriHD_not_markdata-sampe2000.csv')\n",
    "concat2 = pd.read_csv('/ssd8/chih/project/yadong/mark_csv/train_peri_mark_sample_693_JYY.csv')\n",
    "peri_filter_dataset = pd.concat([concat1, concat2])\n",
    "# peri_filter_dataset = peri_filter_dataset['處置其他結束（描述）']\n",
    "# peri_693_dataset = pd.read_csv('../mark_csv/train_peri_mark_sample_693_JYY.csv')[['truth', '處置其他結束（描述）']]\n",
    "# peri_filter_dataset = peri_693_dataset[peri_693_dataset['truth']=='Y']\n",
    "print(peri_filter_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先切割標記後的資料以確保訓練和驗證資料無重疊\n",
    "keyword_col = []\n",
    "for seq in peri_filter_dataset['處置其他結束（描述）'].values.tolist(): #逐筆搜尋pos\n",
    "    seq_sp = str(seq).replace(\"。\",\"，\").replace(\",\",\"，\").replace(\"\\n\",\"\").split('，')\n",
    "    temp_keyword = ''\n",
    "    for pos in positive_context_split_csv:\n",
    "        if str(pos) in seq_sp:\n",
    "            temp_keyword = temp_keyword + str(pos)+'，'\n",
    "    if len(temp_keyword)<1:\n",
    "        temp_keyword = 'Negative_Sequence'\n",
    "    keyword_col.append(temp_keyword)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "peri_filter_dataset['KeyWord_dict'] = keyword_col\n",
    "peri_filter_dataset = peri_filter_dataset[['處置其他結束（描述）', 'KeyWord_dict']]\n",
    "peri_filter_dataset['label'] = [0 if i =='Negative_Sequence' else 1 for i in peri_filter_dataset.KeyWord_dict.tolist()]\n",
    "data_train, data_test = train_test_split(peri_filter_dataset, test_size=0.1, random_state=42, stratify=peri_filter_dataset['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "merage_sentence = []\n",
    "for seq in range(len(data_test)):\n",
    "    rep_seq = data_test.iloc[seq]['處置其他結束（描述）']\n",
    "    rep_seq = str(rep_seq).replace(\"。\",\"，\").replace(\",\",\"，\").replace(\"\\n\",\"\").replace(\";\",\"，\").replace(\"；\",\"，\").split('，')\n",
    "    key_word = data_test.iloc[seq]['KeyWord_dict']\n",
    "    key_word = str(key_word).replace(\"。\",\"，\").replace(\",\",\"，\").replace(\"\\n\",\"\").replace(\";\",\"，\").replace(\"；\",\"，\").split('，')\n",
    "    key_word = [x for x in key_word if x != \"\"]\n",
    "    # if key_word=='Negative_Sequence':\n",
    "    if 'Negative_Sequence' not in key_word:\n",
    "        # print(key_word)\n",
    "        # print(rep_seq)\n",
    "        for pos in key_word:\n",
    "            # merage_sentence.append(['Y',pos])\n",
    "            try:\n",
    "                forward_sentecne = rep_seq[rep_seq.index(pos)-1]+\"，\"+pos\n",
    "                merage_sentence.append(['Y',forward_sentecne])\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                back_sentecne = pos+\"，\"+rep_seq[rep_seq.index(pos)+1]\n",
    "                merage_sentence.append(['Y', back_sentecne])\n",
    "            except:\n",
    "                pass\n",
    "    elif 'Negative_Sequence' in key_word:\n",
    "        for neg in rep_seq:\n",
    "            if neg != '' and neg != ' ':\n",
    "                merage_sentence.append(['N',neg])\n",
    "    # if seq==10:\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.DataFrame(merage_sentence, columns=['Truth', '處置其他結束（描述）']).drop_duplicates(subset=['處置其他結束（描述）'])).to_csv(\"./dataset/PeriHD_Sample-2693_Sentence-merge_internal-test.csv\", encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "merage_sentence = []\n",
    "for seq in range(len(data_train)):\n",
    "    rep_seq = data_train.iloc[seq]['處置其他結束（描述）']\n",
    "    rep_seq = str(rep_seq).replace(\"。\",\"，\").replace(\",\",\"，\").replace(\"\\n\",\"\").replace(\";\",\"，\").replace(\"；\",\"，\").split('，')\n",
    "    key_word = data_train.iloc[seq]['KeyWord_dict']\n",
    "    key_word = str(key_word).replace(\"。\",\"，\").replace(\",\",\"，\").replace(\"\\n\",\"\").replace(\";\",\"，\").replace(\"；\",\"，\").split('，')\n",
    "    key_word = [x for x in key_word if x != \"\"]\n",
    "    # if key_word=='Negative_Sequence':\n",
    "    if 'Negative_Sequence' not in key_word:\n",
    "        # print(key_word)\n",
    "        # print(rep_seq)\n",
    "        for pos in key_word:\n",
    "            # merage_sentence.append(['Y',pos])\n",
    "            try:\n",
    "                forward_sentecne = rep_seq[rep_seq.index(pos)-1]+\"，\"+pos\n",
    "                merage_sentence.append(['Y',forward_sentecne])\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                back_sentecne = pos+\"，\"+rep_seq[rep_seq.index(pos)+1]\n",
    "                merage_sentence.append(['Y', back_sentecne])\n",
    "            except:\n",
    "                pass\n",
    "    elif 'Negative_Sequence' in key_word:\n",
    "        for neg in rep_seq:\n",
    "            if neg != '' and neg != ' ':\n",
    "                merage_sentence.append(['N',neg])\n",
    "    # if seq==10:\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13426"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merage_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.DataFrame(merage_sentence, columns=['Truth', '處置其他結束（描述）']).drop_duplicates(subset=['處置其他結束（描述）'])).to_csv(\"./dataset/PeriHD_Sample-2693_Sentence-merge_internal-train.csv\", encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1121, 2)\n",
      "(1008, 2) (113, 2)\n"
     ]
    }
   ],
   "source": [
    "get_1124_sample_df = pd.read_csv(\"./dataset/train_intra_mark_sample_1124_JYY.csv\")[['truth','處置其他+症狀處置（描述）']]\n",
    "get_1124_sample_df = get_1124_sample_df.rename(columns={'truth':'label'})\n",
    "get_1124_sample_df = get_1124_sample_df.dropna()\n",
    "print(get_1124_sample_df.shape)\n",
    "data_train, data_test = train_test_split(get_1124_sample_df, test_size=0.1, random_state=42, stratify=get_1124_sample_df['label'])\n",
    "data_train.to_csv(\"./dataset/IntraHD_Sample-1124_Sentence-merge_internal-train.csv\", encoding='utf-8-sig', index=False)\n",
    "data_test.to_csv(\"./dataset/IntraHD_Sample-1124_Sentence-merge_internal-test.csv\", encoding='utf-8-sig', index=False)\n",
    "print(data_train.shape, data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', 1000)\n",
    "# pd.set_option('display.max_columns', 20)\n",
    "# data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yd_nlptf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "77a05f791b774c1311eb56e0a2c433b66341ac9a91a33433ad780b7802be94e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
