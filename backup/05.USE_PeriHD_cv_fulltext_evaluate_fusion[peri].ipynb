{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 16:25:02.829769: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-04 16:25:02.955606: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-04 16:25:03.476332: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-04 16:25:03.476407: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-04 16:25:03.476414: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf, os, pandas as pd, numpy as np, pickle, glob\n",
    "from sklearn.model_selection import KFold\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "USD_data_train_pkl = glob.glob(\"/ssd8/chih/project/yadong/predict_baseline_version01/dataset/PeriHD_pickle_save/USD_sample2693_only-merge-sequence_fullcontext/train/*.pkl\")\n",
    "USD_data_test_pkl = glob.glob(\"/ssd8/chih/project/yadong/predict_baseline_version01/dataset/PeriHD_pickle_save/USD_sample2693_only-merge-sequence_fullcontext/test/*.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pk2pf(pkl_list):\n",
    "    data_train = []\n",
    "    for pk in pkl_list:\n",
    "        with open(pk, 'rb') as f:\n",
    "            pk_dict = pickle.load(f)\n",
    "        data_train.append(pk_dict)\n",
    "    data_train = pd.DataFrame(data_train)\n",
    "    \n",
    "    return data_train\n",
    "USD_data_train = pk2pf(USD_data_train_pkl)\n",
    "USD_data_test = pk2pf(USD_data_test_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40726/3208931757.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  USD_data_test_embedding = np.array(USD_data_test['full_embed'].tolist())\n"
     ]
    }
   ],
   "source": [
    "# USD_data_train_embedding = np.array(USD_data_train['full_embed'].tolist())\n",
    "USD_data_test_embedding = np.array(USD_data_test['full_embed'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 26\n"
     ]
    }
   ],
   "source": [
    "# print(len(USD_data_train.label.values)-sum(USD_data_train.label.values), sum(USD_data_train.label.values))\n",
    "print(len(USD_data_test.label.values)-sum(USD_data_test.label.values), sum(USD_data_test.label.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "def create_model(input_shape = (1024,)):\n",
    "  model = tf.keras.Sequential([\n",
    "    keras.layers.Dense(256, activation='relu', input_shape = input_shape),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "  ])\n",
    "  model.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KFold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_weight_path\u001b[39m(fold, train_type):\n\u001b[1;32m      6\u001b[0m     \u001b[39m# return './model_weight/weights_periHD_KFold={}[Fusion].h5'.format(fold)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[39m# return './model_weight/PeriHD/weights_periHD_KFold={}[{}-only-merge-sequnece-resplit].h5'.format(fold,train_type)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m./model_weight/PeriHD/weights_periHD_KFold=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m[\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m-only-merge-sequnece-resplit-periHD-neg+pos].h5\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(fold,train_type)\n\u001b[0;32m----> 9\u001b[0m kfold \u001b[39m=\u001b[39m KFold(n_splits\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     10\u001b[0m gt_in \u001b[39m=\u001b[39m USD_data_test\u001b[39m.\u001b[39mlabel\u001b[39m.\u001b[39mvalues\n\u001b[1;32m     11\u001b[0m gt_ex \u001b[39m=\u001b[39m USD_data_test\u001b[39m.\u001b[39mlabel\u001b[39m.\u001b[39mvalues\n",
      "\u001b[0;31mNameError\u001b[0m: name 'KFold' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, roc_curve, precision_recall_curve, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pylab as plt\n",
    "from tqdm import tqdm\n",
    "def get_weight_path(fold, train_type):\n",
    "    # return './model_weight/weights_periHD_KFold={}[Fusion].h5'.format(fold)\n",
    "    # return './model_weight/PeriHD/weights_periHD_KFold={}[{}-only-merge-sequnece-resplit].h5'.format(fold,train_type)\n",
    "    return './model_weight/PeriHD/weights_periHD_KFold={}[{}-only-merge-sequnece-resplit-periHD-neg+pos].h5'.format(fold,train_type)\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "gt_in = USD_data_test.label.values\n",
    "gt_ex = USD_data_test.label.values\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(12,5))\n",
    "CM_internal = []\n",
    "CM_external = []\n",
    "train_type = 'USD'\n",
    "input_shape  = (512,)\n",
    "Fusion_intranal_embeddings = USD_data_test_embedding\n",
    "Fusion_external_validation_embeddings = USD_data_test_embedding\n",
    "false_pred = pd.DataFrame([], columns=['index', 'Pred score', 'Answer', 'Sentence'])\n",
    "for fold in ['1','2','3','4','5']:\n",
    "# for fold in ['1']:\n",
    "    weight_name = get_weight_path(fold, train_type)\n",
    "    model_cls = create_model(input_shape=input_shape)\n",
    "    model_cls.load_weights(weight_name)\n",
    "    # Internal metric\n",
    "    # split_data_internal = {\"pred\":[], \"truth\": []}\n",
    "    # train_pred_seq_stack =[]\n",
    "    # for (seq_stack, ans) in tqdm(zip(Fusion_intranal_embeddings, gt_in)):\n",
    "    #     test_pred = model_cls.predict(seq_stack,verbose=0)\n",
    "    #     train_pred_seq_stack.append(test_pred)\n",
    "    #     split_data_internal['pred'].append(np.max(test_pred))\n",
    "    #     split_data_internal['truth'].append(ans)\n",
    "    # test_binary_pred1 = (np.array(split_data_internal['pred'])>0.5).astype(np.int8)\n",
    "    # tn, fp, fn, tp = confusion_matrix(split_data_internal['truth'], test_binary_pred1).ravel()\n",
    "    # CM_internal.append([tn, fp, fn, tp])\n",
    "    # fpr, tpr, thresholds = roc_curve(split_data_internal['truth'], split_data_internal['pred'], pos_label=1)\n",
    "    # auc = roc_auc_score(split_data_internal['truth'], split_data_internal['pred'])\n",
    "    # axs[0].plot(fpr, tpr, label = \"Test Fold={} AUC: {}\".format(fold, round(auc, 4)))\n",
    "    # External metric\n",
    "    split_data_external = {\"pred\":[], \"truth\": [], \"index\": []}\n",
    "    test_pred_seq_stack =[]\n",
    "    for (seq_stack, ans) in tqdm(zip(Fusion_external_validation_embeddings, gt_ex)):\n",
    "        test_pred = model_cls.predict(seq_stack, verbose=0)\n",
    "        test_pred_seq_stack.append(test_pred)\n",
    "        split_data_external['pred'].append(np.max(test_pred))\n",
    "        split_data_external['index'].append(np.argmax(test_pred))\n",
    "        split_data_external['truth'].append(ans)\n",
    "    test_binary_pred2 = (np.array(split_data_external['pred'])>0.5).astype(np.int8)\n",
    "    tn, fp, fn, tp = confusion_matrix(split_data_external['truth'], test_binary_pred2).ravel()\n",
    "    CM_external.append([tn, fp, fn, tp])\n",
    "    fpr, tpr, thresholds = roc_curve(split_data_external['truth'], split_data_external['pred'], pos_label=1)\n",
    "    auc = roc_auc_score(split_data_external['truth'], split_data_external['pred'])\n",
    "    axs[1].plot(fpr, tpr, label = \"Test Fold={} AUC: {}\".format(fold, round(auc, 4)))\n",
    "\n",
    "    for idx, (ex_ans, ex_pre, ex_index) in enumerate(zip(split_data_external['truth'], split_data_external['pred'],split_data_external['index'])):\n",
    "        temp = pd.DataFrame([], columns=['index', 'Answer', 'Pred score', 'Sentence'])\n",
    "        temp['index'] = [idx]\n",
    "        temp['Answer'] = [ex_ans]\n",
    "        temp['Pred score'] = [ex_pre]\n",
    "        temp['Sentence'] = [USD_data_test.iloc[idx].full_text[ex_index]]\n",
    "        false_pred = pd.concat([false_pred, temp])\n",
    "        \n",
    "axs[0].plot([0,1],[0,1], linestyle='--')\n",
    "axs[1].plot([0,1],[0,1], linestyle='--')\n",
    "axs[0].legend()\n",
    "axs[1].legend()\n",
    "axs[0].set_xlabel(\"FPR\")\n",
    "axs[0].set_ylabel(\"TPR\")\n",
    "axs[1].set_xlabel(\"FPR\")\n",
    "axs[1].set_ylabel(\"TPR\")\n",
    "axs[0].set_title(f\"[Internal][{train_type}]PeriHD full-sentence ROC-Curve\")\n",
    "axs[1].set_title(f\"[External][{train_type}]PeriHD full-sentence ROC-Curve\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_pred_ths_result = (false_pred['Pred score']>0.5).astype(int)\n",
    "false_pred['Pred Result'] = false_pred_ths_result\n",
    "false_pred_drop = false_pred.drop_duplicates(subset=\"Sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_pred_drop.to_csv('./外部資料Sample預測錯誤結果_Negative和Positive皆做merge.csv', encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 已標記資料效能評估\n",
    "def metric_calc(array_):\n",
    "    tn, fp, fn, tp = array_\n",
    "    acc = (tp+tn)/(tp+tn+fn+fp)\n",
    "    sens = tp/(tp+fn)\n",
    "    spec = tn/(tn+fp)\n",
    "    prec = tp/(tp+fp)\n",
    "    f1 = (2*prec*sens)/(prec+sens)\n",
    "    return acc, prec, sens, spec, f1\n",
    "\n",
    "def get_metric(arr):\n",
    "    mean_arr = np.mean(np.array(arr), axis=0)\n",
    "    std_arr = np.std(np.array(arr), axis=0)\n",
    "    return mean_arr, std_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CM_train = np.array(CM_internal)\n",
    "CM_train = np.array(CM_external)\n",
    "CM_test = np.array(CM_external)\n",
    "T_stack, t_stack = [],[]\n",
    "for T_ in CM_train:\n",
    "    T_stack.append(metric_calc(T_))\n",
    "    \n",
    "for t_ in CM_test:\n",
    "    t_stack.append(metric_calc(t_))\n",
    "#內部資料 - Train & Test\n",
    "mark_train_mean, mark_train_std = get_metric(T_stack)\n",
    "mark_test_mean, mark_test_std = get_metric(t_stack)\n",
    "mark_train = pd.DataFrame(['Accuracy','Precision', 'Sensitivity', 'Specificity', 'F1-score'], columns=[f'{train_type} Metric Train'])\n",
    "for T_, f in zip(T_stack,['fold-1','fold-2','fold-3','fold-4','fold-5']):mark_train[f] = np.round(T_,4)\n",
    "mark_train['Mean'] = np.round(mark_train_mean,4)\n",
    "mark_train['Std'] = np.round(mark_train_std,4)\n",
    "\n",
    "mark_test = pd.DataFrame(['Accuracy','Precision', 'Sensitivity', 'Specificity', 'F1-score'], columns=[f'{train_type} Metric Test'])\n",
    "for t_, f in zip(t_stack,['fold-1','fold-2','fold-3','fold-4','fold-5']):mark_test[f] = np.round(t_,4)\n",
    "mark_test['Mean'] = np.round(mark_test_mean,4)\n",
    "mark_test['Std'] = np.round(mark_test_std,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USD Metric Train</th>\n",
       "      <th>fold-1</th>\n",
       "      <th>fold-2</th>\n",
       "      <th>fold-3</th>\n",
       "      <th>fold-4</th>\n",
       "      <th>fold-5</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.9400</td>\n",
       "      <td>0.9400</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.9400</td>\n",
       "      <td>0.9300</td>\n",
       "      <td>0.9400</td>\n",
       "      <td>0.0063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.8387</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.7879</td>\n",
       "      <td>0.8128</td>\n",
       "      <td>0.0161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sensitivity</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Specificity</td>\n",
       "      <td>0.9189</td>\n",
       "      <td>0.9189</td>\n",
       "      <td>0.9324</td>\n",
       "      <td>0.9189</td>\n",
       "      <td>0.9054</td>\n",
       "      <td>0.9189</td>\n",
       "      <td>0.0085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F1-score</td>\n",
       "      <td>0.8966</td>\n",
       "      <td>0.8966</td>\n",
       "      <td>0.9123</td>\n",
       "      <td>0.8966</td>\n",
       "      <td>0.8814</td>\n",
       "      <td>0.8967</td>\n",
       "      <td>0.0098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  USD Metric Train  fold-1  fold-2  fold-3  fold-4  fold-5    Mean     Std\n",
       "0  Accuracy         0.9400  0.9400  0.9500  0.9400  0.9300  0.9400  0.0063\n",
       "1  Precision        0.8125  0.8125  0.8387  0.8125  0.7879  0.8128  0.0161\n",
       "2  Sensitivity      1.0000  1.0000  1.0000  1.0000  1.0000  1.0000  0.0000\n",
       "3  Specificity      0.9189  0.9189  0.9324  0.9189  0.9054  0.9189  0.0085\n",
       "4  F1-score         0.8966  0.8966  0.9123  0.8966  0.8814  0.8967  0.0098"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mark_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USD Metric Test</th>\n",
       "      <th>fold-1</th>\n",
       "      <th>fold-2</th>\n",
       "      <th>fold-3</th>\n",
       "      <th>fold-4</th>\n",
       "      <th>fold-5</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.9400</td>\n",
       "      <td>0.9400</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.9400</td>\n",
       "      <td>0.9300</td>\n",
       "      <td>0.9400</td>\n",
       "      <td>0.0063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.8387</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.7879</td>\n",
       "      <td>0.8128</td>\n",
       "      <td>0.0161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sensitivity</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Specificity</td>\n",
       "      <td>0.9189</td>\n",
       "      <td>0.9189</td>\n",
       "      <td>0.9324</td>\n",
       "      <td>0.9189</td>\n",
       "      <td>0.9054</td>\n",
       "      <td>0.9189</td>\n",
       "      <td>0.0085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F1-score</td>\n",
       "      <td>0.8966</td>\n",
       "      <td>0.8966</td>\n",
       "      <td>0.9123</td>\n",
       "      <td>0.8966</td>\n",
       "      <td>0.8814</td>\n",
       "      <td>0.8967</td>\n",
       "      <td>0.0098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  USD Metric Test  fold-1  fold-2  fold-3  fold-4  fold-5    Mean     Std\n",
       "0  Accuracy        0.9400  0.9400  0.9500  0.9400  0.9300  0.9400  0.0063\n",
       "1  Precision       0.8125  0.8125  0.8387  0.8125  0.7879  0.8128  0.0161\n",
       "2  Sensitivity     1.0000  1.0000  1.0000  1.0000  1.0000  1.0000  0.0000\n",
       "3  Specificity     0.9189  0.9189  0.9324  0.9189  0.9054  0.9189  0.0085\n",
       "4  F1-score        0.8966  0.8966  0.9123  0.8966  0.8814  0.8967  0.0098"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mark_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yd_nlptf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "77a05f791b774c1311eb56e0a2c433b66341ac9a91a33433ad780b7802be94e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
